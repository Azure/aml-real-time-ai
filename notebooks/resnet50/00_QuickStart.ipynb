{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Hardware Accelerated Models Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will show you how to deploy an image recognition service based on the ResNet 50 classifier in just a few minutes using the Azure Machine Learning Accelerated AI service.  Get more help from our [documentation](https://aka.ms/aml-github-fpga) or email amlfpgafc@microsoft.com.\n",
    "\n",
    "## Request Quota\n",
    "**IMPORTANT:** You must [request quota](https://aka.ms/aml-accel-ai-request-quota) and be approved before you can successfully run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "\n",
    "1. Download and install [Git](https://git-scm.com/downloads) 2.16 or later\n",
    "1. Open a Git prompt and clone this repo:\n",
    "\n",
    "   `git clone https://github.com/Azure/aml-real-time-ai`\n",
    "1. Install conda (Python 3.6):\n",
    "\n",
    "   https://conda.io/miniconda.html\n",
    "1. Open an Anaconda Prompt and run the rest of the commands in the prompt. On Windows the prompt will look like:\n",
    "\n",
    "   `(base) C:\\>`\n",
    "1. Create the environment:\n",
    "\n",
    "   `conda env create -f aml-real-time-ai/environment.yml`\n",
    "1. Activate the environment:\n",
    "   1. Windows:\n",
    "   `conda activate amlrealtimeai`\n",
    "   1. Mac:\n",
    "   `source activate amlrealtimeai`\n",
    "1. Launch the Jupyter notebook browser:\n",
    "\n",
    "   `jupyter notebook` \n",
    "1. In the browser, open this notebook by navigating to notebooks/resnet50/00_QuickStart.ipynb.  (If you're using Chrome, copy and paste the URL with the notebook token into the address bar).\n",
    "\n",
    "1. Run through each cell and enter the appropriate information as necessary (e.g. Azure subscription ID, resource group ID, Model Management Account, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import amlrealtimeai\n",
    "from amlrealtimeai import resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input images as a two-dimensional tensor containing an arbitrary number of images represented a strings\n",
    "import amlrealtimeai.resnet50.utils\n",
    "in_images = tf.placeholder(tf.string)\n",
    "image_tensors = resnet50.utils.preprocess_array(in_images)\n",
    "print(image_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amlrealtimeai.resnet50.model import LocalQuantizedResNet50\n",
    "model_path = os.path.expanduser('~/models')\n",
    "model = LocalQuantizedResNet50(model_path)\n",
    "print(model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.import_graph_def(include_featurizer=False)\n",
    "print(model.classifier_input)\n",
    "print(model.classifier_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service Definition\n",
    "\n",
    "The service definition is a set of files generated from the model that allow us to operationalize locally (for testing) and deploy to the FPGA service. The service definition consists of a pipeline. Each stage in the pipeline is saved as a model checkpoint and any additional information required to execute that stage. The stages will be executed in order on the service, with the output of each stage fed as input to the next stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amlrealtimeai.pipeline import ServiceDefinition, TensorflowStage, BrainWaveStage\n",
    "\n",
    "save_path = os.path.expanduser('~/models/save')\n",
    "service_def_path = os.path.join(save_path, 'service_def.zip')\n",
    "\n",
    "service_def = ServiceDefinition()\n",
    "service_def.pipeline.append(TensorflowStage(tf.Session(), in_images, image_tensors))\n",
    "service_def.pipeline.append(BrainWaveStage(model))\n",
    "service_def.pipeline.append(TensorflowStage(tf.Session(), model.classifier_input, model.classifier_output))\n",
    "service_def.save(service_def_path)\n",
    "print(service_def_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy\n",
    "Go to our [GitHub repo](https://aka.ms/aml-real-time-ai) \"documentation\" folder to learn how to create a Model Management Account and find the required information below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amlrealtimeai import DeploymentClient\n",
    "\n",
    "subscription_id = \"<Your Azure Subscription ID>\"\n",
    "resource_group = \"<Your Azure Resource Group Name>\"\n",
    "model_management_account = \"<Your AzureML Model Management Account Name>\"\n",
    "\n",
    "model_name = \"resnet50-model\"\n",
    "service_name = \"quickstart-service\"\n",
    "\n",
    "deployment_client = DeploymentClient(subscription_id, resource_group, model_management_account)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the service definition to the model management service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = deployment_client.register_model(model_name, service_def_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a service from the model that we registered. If this is a new service then we create it. If you already have a service with this name then the existing service will be updated to use this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = deployment_client.get_service_by_name(service_name)\n",
    "if(service is None):\n",
    "    service = deployment_client.create_service(service_name, model_id)    \n",
    "else:\n",
    "    service = deployment_client.update_service(service.id, model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client\n",
    "We provide a client that can call the service to get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amlrealtimeai import PredictionClient\n",
    "client = PredictionClient(service.ipAddress, service.port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the results we need a mapping to the human readable imagenet classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "classes_entries = requests.get(\"https://raw.githubusercontent.com/Lasagne/Recipes/master/examples/resnet50/imagenet_classes.txt\").text.splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now send an image to the service and get the predictions. Let's see if it can identify a snow leopard.\n",
    "![title](snowleopardgaze.jpg)\n",
    "Snow leopard in a zoo. Photo by Peter Bolliger.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify an image to classify\n",
    "image_file = 'snowleopardgaze.jpg'\n",
    "results = client.score_image(image_file)\n",
    "# map results [class_id] => [confidence]\n",
    "results = enumerate(results)\n",
    "# sort results by confidence\n",
    "sorted_results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "# print top 5 results\n",
    "for top in sorted_results[:5]:\n",
    "    print(classes_entries[top[0]], 'confidence:', top[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "Run the cell below to delete your service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "services = deployment_client.list_services()\n",
    "\n",
    "for service in filter(lambda x: x.name == service_name, services):\n",
    "    print(service.id)\n",
    "    deployment_client.delete_service(service.id)\n",
    "    \n",
    "models = deployment_client.list_models()\n",
    "\n",
    "for model in filter(lambda x: x.name == model_name, models):\n",
    "    print(model.id)\n",
    "    deployment_client.delete_model(model.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You've just created a service that does predictions using an FPGA. The next [notebook](01_ModelBuild.ipynb) shows how to customize the service using transfer learning to classify different types of images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
